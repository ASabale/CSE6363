{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization Pipelines\n",
    "\n",
    "This notebook contains the code for using HuggingFace pipelines for text summarization. The notebook uses the code from \"Natural Language Processing with Transformers\" book by Lewis Tunstall, Leandro von Werra, and Thomas Wolf.\n",
    "\n",
    "## The CNN/Daily Mail Dataset\n",
    "\n",
    "The CNN/Daily Mail dataset is a popular dataset for text summarization. It contains news articles and their summaries. The dataset is available in the HuggingFace datasets library. We will start by loading the dataset and looking at a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (/home/alex/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a540b80e8304b0594eee45b8d7874dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "print(f\"features: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    article: LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter's latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.\n",
      "    highlights: Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][0]\n",
    "print(f\"\"\"\n",
    "    article: {sample['article']}\n",
    "    highlights: {sample['highlights']}\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating popular Models\n",
    "\n",
    "Let's use `HuggingFace` models to evaluate 4 popular model architectures for text summarization. We will use the `pipeline` API to do this. The 4 models are:\n",
    "- GPT2\n",
    "- BART\n",
    "- T5\n",
    "- Pegasus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset['train'][0]['article'][:2000]\n",
    "summaries = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2\n",
    "\n",
    "GPT2 isn't technically a summarization model, but it can generate summaries by appending \"TL;DR\" to the end of the input text. Let's see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:46:10.581391: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package punkt to /home/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# GPT2\n",
    "from transformers import pipeline, set_seed\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "set_seed(42)\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\", framework='pt')\n",
    "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
    "summaries[\"gpt2\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/pytorch2/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# T5\n",
    "pipe = pipeline(\"summarization\", model=\"t5-large\", framework='pt')\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BART\n",
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", framework='pt')\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEGASUS\n",
    "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\", framework='pt')\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUND TRUTH\n",
      "Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund .\n",
      "\n",
      "GPT2\n",
      "I've always liked a good story first, or as much as anyone can tell a good story first...\n",
      "And if your story has the word \"hero\" in it or something which implies heroism, then it's not a story.\n",
      "...If it's your story, and you want\n",
      "\n",
      "T5\n",
      "Harry Potter star Daniel Radcliffe turns 18 on monday .\n",
      "the young actor says he has no plans to fritter his cash away .\n",
      "details of how he'll mark his landmark birthday are under wraps .\n",
      "\n",
      "BART\n",
      "Harry Potter star Daniel Radcliffe turns 18 on Monday.\n",
      "He gains access to a reported £20 million ($41.1 million) fortune.\n",
      "Radcliffe says he has no plans to fritter his cash away on fast cars, drink and parties.\n",
      "His earnings from the first five Potter films have been held in a trust fund.\n",
      "\n",
      "PEGASUS\n",
      "Harry Potter star Daniel Radcliffe gains access to a reported £20 million fortune.\n",
      "Young actor says he has no plans to fritter his cash away.\n",
      "Radcliffe's earnings from the first five Potter films have been held in a trust fund .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"GROUND TRUTH\")\n",
    "print(dataset[\"train\"][0][\"highlights\"])\n",
    "print(\"\")\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(f\"{model_name.upper()}\")\n",
    "    print(summaries[model_name])\n",
    "    print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT2 is clearly not a good model for summarization. It doesn't understand the context of the text and just generates a random summary.\n",
    "\n",
    "T5 was finetuned on this task as well as others, so it performs much better than GPT2. It generates a coherent summary that is mostly correct.\n",
    "\n",
    "BART and PEGASUS were exclusively finetuned on this task, so they perform the best. They generate summaries that are mostly correct and coherent."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Generated Text\n",
    "\n",
    "Given a ground truth summarization, by what metric are models evaluated during training? Two common metrics are ROUGE and BLEU. ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It is a set of metrics for evaluating automatic summarization of texts as well as machine translation. BLEU stands for Bilingual Evaluation Understudy. It is a metric for evaluating the quality of machine translation.\n",
    "\n",
    "## BLEU\n",
    "\n",
    "BLEU compares two texts by counting the number of words in the generated text that occur in the reference and dividing by the total number of words in the generated text. The higher the BLEU score, the better the generated text. Each word is counted only as many times as it occurs in the reference text. For example, if the reference text contains the word \"the\" 3 times, but the generated text contains the word \"the\" 5 times, the word \"the\" is only counted 3 times.\n",
    "\n",
    "Since multiple translations are valid, BLEU is calculated by aggregating the BLEU score for each translation. This assumes that we have multiple targets in the test set.\n",
    "\n",
    "The raw BLEU score favors shorter translations. This is because shorter translations are more likely to contain words that are in the reference text. To account for this, the authors introduce a brevity penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>8.116698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[6, 5, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[16.67, 10.0, 6.25, 4.17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0\n",
       "score                        8.116698\n",
       "counts                   [1, 0, 0, 0]\n",
       "totals                   [6, 5, 4, 3]\n",
       "precisions  [16.67, 10.0, 6.25, 4.17]\n",
       "bp                                1.0\n",
       "sys_len                             6\n",
       "ref_len                             5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Score for repeated words\n",
    "prediction = [\"Naomi Naomi Naomi Naomi Naomi Naomi\"]\n",
    "reference = [\"Naomi went to the store\"]\n",
    "results = bleu_metric.compute(predictions=prediction, references=reference)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>49.760939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[4, 2, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[4, 3, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[100.0, 66.67, 50.0, 50.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>0.778801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "score                        49.760939\n",
       "counts                    [4, 2, 1, 0]\n",
       "totals                    [4, 3, 2, 1]\n",
       "precisions  [100.0, 66.67, 50.0, 50.0]\n",
       "bp                            0.778801\n",
       "sys_len                              4\n",
       "ref_len                              5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A more sensible comparison\n",
    "prediction = [\"Naomi went to store\"]\n",
    "reference = [\"Naomi went to the store\"]\n",
    "results = bleu_metric.compute(predictions=prediction, references=reference)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE\n",
    "\n",
    "ROUGE was developed specifically for summarization. It is similar to BLEU, but it also looks at the number of different $n$-grams in the *reference* text that occur in the *generated* texts. We will evaluate four different version of ROGUE:\n",
    "1. ROUGE-1: looks at the number of unigrams in the reference text that occur in the generated text\n",
    "2. ROUGE-2: looks at the number of bigrams in the reference text that occur in the generated text\n",
    "3. ROUGE-L: looks at the longest common subsequence between the reference text and the generated text\n",
    "4. ROUGE-Lsum: calculates the score per sentence over the whole summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.091954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.575342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.717391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rouge1    rouge2    rougeL  rougeLsum\n",
       "gpt2     0.114943  0.000000  0.068966   0.091954\n",
       "t5       0.575342  0.450704  0.547945   0.575342\n",
       "bart     0.717391  0.511111  0.652174   0.717391\n",
       "pegasus  0.800000  0.692308  0.800000   0.800000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "reference = dataset[\"train\"][0][\"highlights\"]\n",
    "records = []\n",
    "\n",
    "for model_name in summaries:\n",
    "    prediction = summaries[model_name]\n",
    "    score = rouge_metric.compute(predictions=[prediction], references=[reference])\n",
    "    records.append(score)\n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
