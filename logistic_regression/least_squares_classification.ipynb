{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda774fd-eb24-4e0b-9ef1-48776d8695e9",
   "metadata": {},
   "source": [
    "# Classification with Least Squares\n",
    "\n",
    "This notebook demonstrates how to implement a $K$-class classifier and solve for the parameters using a least-squares approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34ca19f-a43f-47c8-81f7-3e0e51bf2dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mlxtend.plotting.decision_regions import plot_decision_regions\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ec92d49-375a-425b-a04d-db5a071ac3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(targets, nb_classes):\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape)+[nb_classes])\n",
    "\n",
    "\n",
    "class LinearDiscriminant:        \n",
    "    def fit(self, data, targets):\n",
    "        num_classes = np.max(targets, axis=0) + 1\n",
    "        data = np.concatenate((np.ones((data.shape[0], 1)), data), axis=-1)\n",
    "        targets = get_one_hot(targets, num_classes)\n",
    "        self.weights_ = np.linalg.inv(data.T @ data) @ data.T @ targets\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"Classify input sample(s)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array-like, [n_samples, n_features]\n",
    "            Samples\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        result : array-like, int, [n_samples]\n",
    "            Corresponding prediction(s)\n",
    "        \"\"\"\n",
    "        # Add constant for bias parameter\n",
    "        x = np.concatenate((np.ones((x.shape[0], 1)), x), axis=-1)\n",
    "            \n",
    "        return np.argmax(self.weights_.T @ x.T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab6bcfa7-643d-4f2b-a9a3-f700afd699bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d5b0d806854fcab6d1450f10b14a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6f68cde7d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate some data\n",
    "n_classes = 3\n",
    "X, Y = make_classification(200, 2, n_redundant=0, n_classes=n_classes, n_clusters_per_class=1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X[:, 0], X[:, 1], c=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bda7878-e872-4306-90f7-09cab069eeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error = 22.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bee3206998d4333bb87b68225aabdfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LinearDiscriminant()\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "# Measure number of misclassifications\n",
    "error = np.sum(np.abs(classifier.predict(X) - Y))\n",
    "print(f\"Error = {(error / 200) * 100:1.2f}%\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plot_decision_regions(X, Y, classifier)\n",
    "fig.add_subplot(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27460336-6946-427b-bc65-c535ac26f9e1",
   "metadata": {},
   "source": [
    "# Sensitivity to Outliers\n",
    "\n",
    "A major downside to least squares models is their sensitivity to outliers.\n",
    "Consider the dataset below which has a relatively balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a99e9b50-27b4-4b3f-a339-bae3aa63038e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1df10741f944657a3275a1550e26cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6f68463610>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_samples = np.random.multivariate_normal([-1, 1], [[0.2, 0], [0, 0.2]], 100)\n",
    "b_samples = np.random.multivariate_normal([1, -1], [[0.2, 0], [0, 0.2]], 100)\n",
    "a_targets = np.zeros(100).astype(int)  # Samples from class A are assigned a class value of 0.\n",
    "b_targets = np.ones(100).astype(int)  # Samples from class B are assigned a class value of 1.\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(a_samples[:, 0], a_samples[:, 1], c='b')\n",
    "ax.scatter(b_samples[:, 0], b_samples[:, 1], c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30446a6-aba2-4ef0-b615-0dc69583b53a",
   "metadata": {},
   "source": [
    "The data is clearly linearly separable, so a linear classifier should achieve 100% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb8bfd01-9610-40f3-a790-1e6d585dc4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error = 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75d3a6190c84206917852989a364a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((a_samples, b_samples))\n",
    "Y = np.concatenate((a_targets, b_targets))\n",
    "\n",
    "classifier = LinearDiscriminant()\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "# Measure number of misclassifications\n",
    "error = np.sum(np.abs(classifier.predict(X) - Y))\n",
    "print(f\"Error = {(error / 200) * 100:1.2f}%\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plot_decision_regions(X, Y, classifier)\n",
    "fig.add_subplot(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dfce76-1438-4afd-bba1-6623d8a029c7",
   "metadata": {},
   "source": [
    "As expected, this is a perfect dataset for a linear classifier.\n",
    "Let's now look at how moving some of the points away from the central cluster will affect the resulting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22c6e0be-9c5f-4a9a-87d5-900417daf352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/cse6363/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dde8231d2d94dac9a4cb2c05b5dd55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6f67602e10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_samples1 = np.random.multivariate_normal([-1, 1], [[0.2, 0], [0.2, 0.2]], 80)\n",
    "a_samples2 = np.random.multivariate_normal([-2, 6], [[0.2, 0], [0, 0.2]], 20)\n",
    "a_samples = np.concatenate((a_samples1, a_samples2))\n",
    "b_samples = np.random.multivariate_normal([1, -1], [[0.2, 0], [0, 0.2]], 100)\n",
    "a_targets = np.zeros(100).astype(int)  # Samples from class A are assigned a class value of 0.\n",
    "b_targets = np.ones(100).astype(int)  # Samples from class B are assigned a class value of 1.\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(a_samples[:, 0], a_samples[:, 1], c='b')\n",
    "ax.scatter(b_samples[:, 0], b_samples[:, 1], c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a68467f-4845-484e-b110-26537fae5022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error = 3.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae6f219fbfd42408f49bbccb5235e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((a_samples, b_samples))\n",
    "Y = np.concatenate((a_targets, b_targets))\n",
    "\n",
    "classifier = LinearDiscriminant()\n",
    "classifier.fit(X, Y)\n",
    "\n",
    "# Measure number of misclassifications\n",
    "error = np.sum(np.abs(classifier.predict(X) - Y))\n",
    "print(f\"Error = {(error / 200) * 100:1.2f}%\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plot_decision_regions(X, Y, classifier)\n",
    "fig.add_subplot(ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cse6363] *",
   "language": "python",
   "name": "conda-env-cse6363-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
