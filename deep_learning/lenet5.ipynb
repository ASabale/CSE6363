{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7c6ba42-f5d2-4044-a80b-ded44bdad186",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "In this notebook, we will implement one of the first successful CNNs for handwritten digit recognition and adapt it to work with CIFAR10 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed0cd82-86a4-4d3c-9b85-a0825aeb2b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bd8cef-0b41-4928-993a-b0b00a44768f",
   "metadata": {},
   "source": [
    "## LeNet5\n",
    "\n",
    "The original network was meant for $28 \\times 28$ single-channel images.\n",
    "Our data is $32 \\times 32 \\times 3$. The first change is to update the number of input channels in the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2829e18-f696-403b-a595-ad88d9fd82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5), # nn.Conv2d(1, 6, 5) -> nn.Conv2d(3, 6, 5)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.estimator = nn.Sequential(\n",
    "            nn.Linear(400, 120), # nn.Linear(256, 120) -> nn.Linear(400, 120)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        return self.estimator(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610620f-7500-43c6-9d26-e2ece31a4f1f",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf4afe4-247c-4fe7-8d46-28ad0298c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = transforms.functional.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "        \n",
    "        \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeb7a1e-8d39-4ef4-b4a7-94f834a16ad0",
   "metadata": {},
   "source": [
    "## Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3499b30c-66b3-4319-98c5-46601090edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, logger=None):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (input, target) in pbar:\n",
    "        \n",
    "        # input = input.cuda()\n",
    "        # target = target.cuda()\n",
    "\n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output = output.float()\n",
    "        loss = loss.float()\n",
    "\n",
    "        prec = accuracy(output.data, target)[0]\n",
    "        losses.update(loss.item(), input.shape[0])\n",
    "        top1.update(prec.item(), input.shape[0])\n",
    "        \n",
    "        if i % print_frequency == 0:\n",
    "            pbar.set_description(\"Epoch [%d]\\t Loss %.2f\\t Prec@1 %.3f (%.3f)\" % (epoch, losses.avg, top1.val, top1.avg))\n",
    "            if logger:\n",
    "                logger.add_scalar(\"training loss\",\n",
    "                                  loss.item(),\n",
    "                                  epoch * len(dataloader) + i)\n",
    "           \n",
    "        \n",
    "def val_loop(dataloader, model, loss_fn, logger=None):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (input, target) in pbar:\n",
    "        \n",
    "        # input = input.cuda()\n",
    "        # target = target.cuda()\n",
    "\n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output = output.float()\n",
    "        loss = loss.float()\n",
    "        \n",
    "        prec = accuracy(output.data, target)[0]\n",
    "        losses.update(loss.item(), input.shape[0])\n",
    "        top1.update(prec.item(), input.shape[0])\n",
    "\n",
    "        if i % print_frequency == 0:\n",
    "            pbar.set_description(\"Epoch [%d]\\t Loss %.2f\\t Prec@1 %.3f (%.3f)\" % (epoch, losses.avg, top1.val, top1.avg))\n",
    "            if logger:\n",
    "                logger.add_scalar(\"validation loss\",\n",
    "                                  loss.item(),\n",
    "                                  epoch * len(dataloader) + i)\n",
    "    \n",
    "    if logger:\n",
    "        logger.add_scalar(\"validation accuracy\",\n",
    "                          top1.avg,\n",
    "                          epoch)\n",
    "            \n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (input, target) in pbar:\n",
    "        \n",
    "        input = input.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        output = output.float()\n",
    "        loss = loss.float()\n",
    "\n",
    "        prec = accuracy(output.data, target)[0]\n",
    "        losses.update(loss.item(), input.shape[0])\n",
    "        top1.update(prec.item(), input.shape[0])\n",
    "\n",
    "    # Print result\n",
    "    print(f\"Average Loss: {losses.avg:>8f}\\nAccuracy: {top1.avg}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fcabbe-c41d-4fca-83c9-a19a61838a40",
   "metadata": {},
   "source": [
    "# Model Hyperparameters and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357b811a-bde8-4f1c-891a-cbf2a9b78829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3\n",
    "epochs = 5\n",
    "print_frequency = 100\n",
    "\n",
    "model = LeNet5()\n",
    "# model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc4036-360b-4c7f-921e-5a9752e929f0",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ffa2ce2-6b06-4d24-baea-bf972b40048c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# root_path = \"/home/alex/Data/CIFAR10\"\n",
    "root_path = \"/Users/ajd/Data/CIFAR10\"\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root_path, train=True, transform=transforms.Compose([\n",
    "    transforms.RandAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "]), download=True)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * .95)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True,\n",
    "    num_workers=8, pin_memory=False)\n",
    "\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=8, pin_memory=False)\n",
    "\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR10(root_path, train=False, transform=transforms.Compose([                                                                     \n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=8, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad41b7-53aa-4034-a925-96815af9e1a3",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d8bda7f-a37a-45c9-aa65-acc3e99828e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944a1fc9df9d4174a7a452e075b48fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507f1cca1ad747a2ab3069a3c5207354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fm/7hrc_qfs3d781dd3tv3668040000gn/T/ipykernel_74622/3817194633.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/fm/7hrc_qfs3d781dd3tv3668040000gn/T/ipykernel_74622/89506229.py\u001b[0m in \u001b[0;36mval_loop\u001b[0;34m(dataloader, model, loss_fn, logger)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cse6363/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "logger = SummaryWriter(\"runs/lenet5_basic\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loop(train_dataloader, model, criterion, optimizer, logger)\n",
    "    val_loop(val_dataloader, model, criterion, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "262941a4-0c79-4c11-9ddd-f6309f61e916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ec7a921d114aad9b58ec86d6eac851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 2.722911\n",
      "Accuracy: 54.57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(test_dataloader, model, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('cse6363')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec212871e462c9aca7e468d49c2f2a64f2148e2f99b4852dc4e63b4d9704736d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
