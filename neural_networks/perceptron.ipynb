{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c26d0ec9-7647-47b6-900b-7bdde8dd48f3",
   "metadata": {},
   "source": [
    "# Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d6eaf-c9bb-42a2-b949-9f1443d938c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3af109-a0e4-4d45-9fa9-659712b84201",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_samples = np.random.multivariate_normal([-1, 1], [[0.1, 0], [0, 0.1]], 100)\n",
    "b_samples = np.random.multivariate_normal([1, -1], [[0.1, 0], [0, 0.1]], 100)\n",
    "a_targets = np.ones(100) * -1  # Samples from class A are assigned a class value of -1.\n",
    "b_targets = np.ones(100)  # Samples from class B are assigned a class value of 1.\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(a_samples[:, 0], a_samples[:, 1], c='b')\n",
    "ax.scatter(b_samples[:, 0], b_samples[:, 1], c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05c7a3-733f-4d38-aa4b-83dc596fcd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_step(x):\n",
    "    \"\"\"Original Perceptron step function.\"\"\"\n",
    "    out = x.copy()\n",
    "    out[x < 0] = -1\n",
    "    out[x >= 0] = 1\n",
    "    return out\n",
    "\n",
    "\n",
    "def dot(w, x):\n",
    "    x_bias = np.concatenate((np.ones((x.shape[0], 1)), x), axis=1)\n",
    "    return w @ x_bias.T\n",
    "\n",
    "\n",
    "def calc_decision_boundary(weights):\n",
    "    \"\"\"Compute decision boundary given the parameters.\n",
    "    Assumes the bias parameter is the first weight.\"\"\"\n",
    "    x = -weights[0] / weights[1]\n",
    "    y = -weights[0] / weights[2]\n",
    "    m = -y / x\n",
    "    return np.array([m, y])\n",
    "\n",
    "\n",
    "def p_loss(predictions, targets):\n",
    "    \"\"\"Original Perceptron loss formulation.\"\"\"\n",
    "    \n",
    "    # The original loss only considered misclassifications\n",
    "    predictions[targets == predictions] = 0\n",
    "    \n",
    "    return -np.dot(predictions, targets)\n",
    "\n",
    "\n",
    "def p_update(weights, sample, prediction, target, eta=1):\n",
    "    \"\"\"Original Perceptron update step.\"\"\"\n",
    "    \n",
    "    if prediction == target:\n",
    "        return weights\n",
    "    \n",
    "    x_bias = np.insert(sample, 0, 1)\n",
    "\n",
    "    w_update = weights + eta * x_bias * target\n",
    "\n",
    "    return w_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7c30a-0574-46c2-abd3-ee961b44cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight Initialization\n",
    "weights = np.random.uniform(-1, 1, size=(3,))\n",
    "print(\"Weights: {}\".format(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb5237-eafb-4ef7-a9c4-f1786e3926e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass -- use input from the blue distribution centered at (-1, 1)\n",
    "x = np.array([[-1.0, 1.0]])\n",
    "y = dot(weights, x)\n",
    "print(\"Before step function: {}\".format(y[0]))\n",
    "\n",
    "# Step function\n",
    "out = p_step(y)\n",
    "print(\"Final prediction: {}\".format(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398ef20-2fd7-47f8-bdfd-5118d0d39d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Parameters\n",
    "# print(weights)\n",
    "# weights = np.array([0.1, -0.91290713, -0.19996809]) \n",
    "\n",
    "# For visualizing the line\n",
    "m, b = calc_decision_boundary(weights)\n",
    "print(\"Slope: {}\\nY-Intercept: {}\".format(m, b))\n",
    "\n",
    "# If the slope is undefined, it is vertical.\n",
    "if weights[2] != 0:\n",
    "    x = np.linspace(-3, 3, 100)\n",
    "    y = m * x + b\n",
    "else:\n",
    "    x = np.zeros(100)\n",
    "    y = np.linspace(-3, 3, 100) + b\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x, y, c='g')\n",
    "ax.scatter(a_samples[:, 0], a_samples[:, 1], c='b')\n",
    "ax.scatter(b_samples[:, 0], b_samples[:, 1], c='r')\n",
    "ax.set_xlim([-2, 2])\n",
    "ax.set_ylim([-2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1dc70-61c4-4d40-9d45-19dbedff38ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make a prediction\n",
    "# Linear combination of weights and input\n",
    "y_a = dot(weights, a_samples)\n",
    "y_b = dot(weights, b_samples)\n",
    "\n",
    "# Step-wise activation function\n",
    "a_pred = p_step(y_a)\n",
    "b_pred = p_step(y_b)\n",
    "\n",
    "# Step 2: Calculate the loss\n",
    "a_loss = p_loss(a_pred, a_targets)\n",
    "b_loss = p_loss(b_pred, b_targets)\n",
    "print(\"Loss A = {}\".format(a_loss))\n",
    "print(\"Loss B = {}\".format(b_loss))\n",
    "\n",
    "# Combine and normalize the error between 0 and 1.\n",
    "# loss = np.concatenate((l1_a, l1_b)).mean()\n",
    "# print(\"Normalized loss = {}\".format(loss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1936443a-5c67-4735-97de-74a75e796284",
   "metadata": {},
   "source": [
    "# Update Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d1490-2c22-4c7f-9be8-bfd12f766e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "samples = np.concatenate((a_samples, b_samples))\n",
    "pred = np.concatenate((a_pred, b_pred))\n",
    "targets = np.concatenate((a_targets, b_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fed750-d7fe-4ed2-88fd-5cf8434f0b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Parameters\n",
    "# print(weights)\n",
    "\n",
    "# Step 3: Update the weights\n",
    "for i in range(pred.shape[0]):\n",
    "    weights = p_update(weights, samples[i], pred[i], targets[i])\n",
    "\n",
    "# Classifier Parameters\n",
    "# print(weights)\n",
    "\n",
    "# For visualizing the line\n",
    "m, b = calc_decision_boundary(weights)\n",
    "print(\"Slope: {}\\nY-Intercept: {}\".format(m, b))\n",
    "\n",
    "y = dot(weights, samples)\n",
    "\n",
    "# Step-wise activation function\n",
    "pred = p_step(y)\n",
    "loss = p_loss(pred, targets)\n",
    "print(\"Loss = {}\".format(loss))\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axline([0, b], slope=m, c=[0, 0, 0])\n",
    "ax.scatter(a_samples[:, 0], a_samples[:, 1], c='b')\n",
    "ax.scatter(b_samples[:, 0], b_samples[:, 1], c='r')\n",
    "ax.set_xlim([-2, 2])\n",
    "ax.set_ylim([-2, 2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "302e6411-9b48-41ba-82fb-ba2cebbd4f87",
   "metadata": {},
   "source": [
    "In practice, we implement this to run for $n$ steps before updating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4be5a9-f7bd-42aa-8378-52ccd6075caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "for i in range(n):\n",
    "    y = dot(weights, samples)\n",
    "\n",
    "    # Step-wise activation function\n",
    "    pred = p_step(y)\n",
    "    loss = p_loss(pred, targets)\n",
    "\n",
    "    weights = p_update(weights, samples[i], pred[i], targets[i])\n",
    "\n",
    "# Classifier Parameters\n",
    "print(weights)\n",
    "\n",
    "# For visualizing the line\n",
    "m, b = calc_decision_boundary(weights)\n",
    "print(\"Slope: {}\\nY-Intercept: {}\".format(m, b))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axline([0, b], slope=m, c=[0, 0, 0])\n",
    "ax.scatter(a_samples[:, 0], a_samples[:, 1], c='b')\n",
    "ax.scatter(b_samples[:, 0], b_samples[:, 1], c='r')\n",
    "ax.set_xlim([-2, 2])\n",
    "ax.set_ylim([-2, 2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse6363",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "53ef4221aa1ddcebf8ffe152ce07046cd10cba6b415b9c2173d01d52e94eb207"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
