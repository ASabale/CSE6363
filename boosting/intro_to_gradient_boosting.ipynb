{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Size of the house (in square feet) and age of the house (in years)\n",
    "X = np.array([[1500, 5], [2000, 3], [2500, 10], [3000, 1]])\n",
    "# Price of the house (in dollars)\n",
    "y = np.array([300000, 400000, 450000, 600000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use a decision stump as our first weak learner, or we could use the average of the target values. Since the mean is easier to compute, we'll go with that.\n",
    "\n",
    "$$\n",
    "\\bar{y} = \\frac{300000 + 400000 + 450000 + 600000}{4} = 437500\n",
    "$$\n",
    "\n",
    "Next, we will compute the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_price = np.mean(y)\n",
    "residuals = y - mean_price\n",
    "\n",
    "# Compute the baseline error\n",
    "baseline_error = mean_squared_error(y, [mean_price] * len(y))\n",
    "print(\"Baseline error: {}\".format(np.sqrt(baseline_error)))\n",
    "\n",
    "print(\"Mean price: {}\".format(mean_price))\n",
    "print(\"Residuals: {}\".format(residuals))\n",
    "\n",
    "# Create a decision tree regressor and fit it to the data\n",
    "regressor = DecisionTreeRegressor(max_depth=2)\n",
    "regressor.fit(X, residuals)\n",
    "\n",
    "# Make predictions on the training data\n",
    "predictions = regressor.predict(X)\n",
    "print(\"Predictions: {}\".format(predictions))\n",
    "\n",
    "# Update the predictions with the residuals\n",
    "tree1_predictions = predictions + mean_price\n",
    "\n",
    "# Compute the error\n",
    "errors = mean_squared_error(y, tree1_predictions)\n",
    "print(\"New error: {}\".format(np.sqrt(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By boosting the original predictions with a single decision tree, the error was reduced from $108253.18$ to $17677.67$. The algorithm continues for as many trees as we specify. The final prediction is the sum of the predictions from all the trees.\n",
    "\n",
    "Try modifying the number of trees below and see how the error changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the updated residuals\n",
    "residuals = y - tree1_predictions\n",
    "predictions = tree1_predictions\n",
    "\n",
    "# Boost multiple times\n",
    "num_boosts = 5\n",
    "for i in range(num_boosts):\n",
    "    # Fit the regressor to the updated residuals\n",
    "    regressor.fit(X, residuals)\n",
    "\n",
    "    # Make predictions on the training data\n",
    "    predictions += regressor.predict(X)\n",
    "\n",
    "    # Update the residuals\n",
    "    residuals = y - predictions\n",
    "\n",
    "# Make predictions on the training data\n",
    "print(\"Final predictions: {}\".format(predictions))\n",
    "\n",
    "# Compute the error\n",
    "errors = mean_squared_error(y, predictions)\n",
    "print(\"Final error: {}\".format(np.sqrt(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, let's see how `xgboost` does with the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use xgboost on the same data\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create the model\n",
    "xgb_regressor = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "xgb_regressor.fit(X, y)\n",
    "\n",
    "# Make predictions on the training data\n",
    "predictions = xgb_regressor.predict(X)\n",
    "print(\"Predictions: {}\".format(predictions))\n",
    "\n",
    "# Compute the error\n",
    "errors = mean_squared_error(y, predictions)\n",
    "print(\"New error: {}\".format(np.sqrt(errors)))\n",
    "\n",
    "# Print the model\n",
    "print(xgb_regressor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse6363",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
