{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 19:27:27.853769: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34ec30658c24adaaeba47d4eda96980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672decaa71fd40d7b10809a974bf5b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63bd0caacf54d9ab4ce03800561d29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad0834086b54324a8cff9c8521965d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e448bfc1c1344038a59110150a429c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.746867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label     score\n",
       "0  LABEL_2  0.746867"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Text Classification\n",
    "classifier = pipeline('sentiment-analysis', framework='pt', model='cardiffnlp/twitter-roberta-base-sentiment')\n",
    "text = \"This wasn't my favorite episode, but I still enjoyed it.\"\n",
    "outputs = classifier(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e974524923e429e985c3c4217b701a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880f23143c6b4110ad3f5f423c911d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e3d5241ac44166ba230fbd6d522dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e440d57e81ce49199fb23fa0f359813b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd81e79fc6a464192c99f614bff4326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297e8ee7b83c4aea96ec2c0acc0e4dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>score</th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>1</td>\n",
       "      <td>James</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.999498</td>\n",
       "      <td>2</td>\n",
       "      <td>Holden</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-MISC</td>\n",
       "      <td>0.935776</td>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0.632716</td>\n",
       "      <td>11</td>\n",
       "      <td>##oc</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0.921614</td>\n",
       "      <td>12</td>\n",
       "      <td>##ina</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0.956059</td>\n",
       "      <td>13</td>\n",
       "      <td>##nte</td>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>0.991403</td>\n",
       "      <td>19</td>\n",
       "      <td>Ty</td>\n",
       "      <td>79</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I-LOC</td>\n",
       "      <td>0.970041</td>\n",
       "      <td>20</td>\n",
       "      <td>##cho</td>\n",
       "      <td>81</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-LOC</td>\n",
       "      <td>0.997077</td>\n",
       "      <td>21</td>\n",
       "      <td>Station</td>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entity     score  index     word  start  end\n",
       "0   B-PER  0.999722      1    James      0    5\n",
       "1   I-PER  0.999498      2   Holden      6   12\n",
       "2  B-MISC  0.935776     10        R     43   44\n",
       "3  I-MISC  0.632716     11     ##oc     44   46\n",
       "4  I-MISC  0.921614     12    ##ina     46   49\n",
       "5  I-MISC  0.956059     13    ##nte     49   52\n",
       "6   B-LOC  0.991403     19       Ty     79   81\n",
       "7   I-LOC  0.970041     20    ##cho     81   84\n",
       "8   I-LOC  0.997077     21  Station     85   92"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Named Entity Recognition\n",
    "ner = pipeline('ner', framework='pt', model='dslim/bert-base-NER')\n",
    "text = \"James Holden and his crew are on board the Rocinante. They are heading towards Tycho Station.\"\n",
    "outputs = ner(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d8acb5427f47eca693467aab4a1d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/657 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80686343c614c73bd3af4c7fc77d151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/711M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945b7fb6d2304f60988f41737ed62373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bc147d1dc342629d740de21f03ec83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6431ccb5a3d4dfd8019b22fb6d8fb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.907091</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>1.5B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start  end answer\n",
       "0  0.907091     31   35   1.5B"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question Answering\n",
    "question_answerer = pipeline('question-answering', framework='pt', model='mrm8488/bert-multi-cased-finetuned-xquadv1')\n",
    "context = \"\"\"Our largest model, GPT-2,\n",
    "is a 1.5B parameter Transformer that achieves\n",
    "state of the art results on 7 out of 8 tested language\n",
    "modeling datasets in a zero-shot setting\n",
    "but still underfits WebText. Samples from the\n",
    "model reflect these improvements and contain\n",
    "coherent paragraphs of text. These findings suggest\n",
    "a promising path towards building language\n",
    "processing systems which learn to perform tasks from\n",
    "their naturally occurring demonstrations.\"\"\"\n",
    "\n",
    "question = \"How many parameters does GPT-2 have?\"\n",
    "outputs = question_answerer(question=question, context=context)\n",
    "pd.DataFrame(outputs, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multitask training is a promising framework for improving general performance.\n"
     ]
    }
   ],
   "source": [
    "# Text Summarization\n",
    "summarizer = pipeline('summarization', framework='pt', model='google/pegasus-xsum')\n",
    "text = \"\"\"Machine learning systems now excel (in expectation) at\n",
    "tasks they are trained for by using a combination of large\n",
    "datasets, high-capacity models, and supervised learning.\n",
    "Yet these systems are brittle and sensitive to\n",
    "slight changes in the data distribution\n",
    "and task specification. Current\n",
    "systems are better characterized as narrow experts rather than\n",
    "competent generalists. We would like to move towards more\n",
    "general systems which can perform many tasks – eventually\n",
    "without the need to manually create and label a training\n",
    "dataset for each one.\n",
    "The dominant approach to creating ML systems is to col-\n",
    "lect a dataset of training examples demonstrating correct\n",
    "behavior for a desired task, train a system to imitate these\n",
    "behaviors, and then test its performance on independent\n",
    "and identically distributed (IID) held-out examples. This\n",
    "has served well to make progress on narrow experts. But\n",
    "the often erratic behavior of captioning models, reading comprehension systems,\n",
    "and image classifiers on the diversity\n",
    "and variety of possible inputs highlights some of the short-\n",
    "comings of this approach.\n",
    "Our suspicion is that the prevalence of single task training\n",
    "on single domain datasets is a major contributor to the lack\n",
    "of generalization observed in current systems. Progress\n",
    "towards robust systems with current architectures is likely\n",
    "to require training and measuring performance on a wide\n",
    "range of domains and tasks. Recently, several benchmarks\n",
    "have been proposed such as GLUE and\n",
    "decaNLP to begin studying this.\n",
    "Multitask learning is a promising framework\n",
    "for improving general performance. However, multitask\n",
    "training in NLP is still nascent. Recent work reports\n",
    "modest performance improvements (Yogatama et al.,\n",
    "2019) and the two most ambitious efforts to date have\n",
    "trained on a total of 10 and 17 (dataset, objective)\n",
    "pairs respectively. From a meta-learning perspective, each (dataset,\n",
    "objective) pair is a single training example sampled\n",
    "from the distribution of datasets and objectives. Current\n",
    "ML systems need hundreds to thousands of examples to\n",
    "induce functions which generalize well. This suggests that\n",
    "multitask training many need just as many effective training\n",
    "pairs to realize its promise with current approaches. It will\n",
    "be very difficult to continue to scale the creation of datasets\n",
    "and the design of objectives to the degree that may be required\n",
    "to brute force our way there with current techniques.\n",
    "This motivates exploring additional setups for performing\n",
    "multitask learning.\"\"\"\n",
    "\n",
    "outputs = summarizer(text)\n",
    "print(outputs[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae54b1096dc46578874894759ccc48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/pytorch2/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous pouvez en dire beaucoup sur un endroit par la façon dont ils traitent leurs gens.\n"
     ]
    }
   ],
   "source": [
    "# Translation\n",
    "translator = pipeline('translation_en_to_fr', framework='pt', model='Helsinki-NLP/opus-mt-en-fr')\n",
    "text = \"You can tell a lot about a place by how they treat their people.\"\n",
    "outputs = translator(text, clean_up_tokenization_spaces=True)\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHIP INTERIOR.\n",
      "\n",
      "HOLDEN: I'd really prefer tacos over more spaghetti.\n",
      "\n",
      "NAOMI: That's the only thing we have right now.\n",
      "\n",
      "MILLER: ��We've got a lot in store for you and we can just make tacos, and if you want to bring our son (inaudible). You know, I'm out there getting some tacos, so...\n",
      "\n",
      "MILLER: No.\n",
      "\n",
      "MILLER: �We�re all about tacos,� and we have our own kind of tacos I think we just went there with our boy.\n",
      "\n",
      "MILLER: We�ve got so many different kinds this year,� you know, all kinds of different kinds of tacos, but this kid made one, right?\n",
      "\n",
      "NAOMI: Yes.\n",
      "\n",
      "HOLDEN: We have a big box. Our son...\n",
      "\n",
      "NAOMI:...we made some different versions of it\n"
     ]
    }
   ],
   "source": [
    "# Text Generation\n",
    "generator = pipeline('text-generation', framework='pt', model='gpt2')\n",
    "text = \"SHIP INTERIOR.\\n\\nHOLDEN: I'd really prefer tacos over more spaghetti.\\n\\nNAOMI: That's the only thing we have right now.\\n\\nMILLER: \"\n",
    "outputs = generator(text, max_length=200)\n",
    "print(outputs[0]['generated_text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
